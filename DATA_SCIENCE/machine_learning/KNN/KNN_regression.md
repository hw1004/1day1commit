# KNN 회귀
## 지도학습과 비지도 학습
- 지도 학습: 데이터의 결정값(정답)이 있는 경우
  - **분류**: 샘플을 몇 개의 클래스로 분류하는 것
  - **회귀**: 임의의 연속적인 수치를 예측하는 것 (두 변수 사이의 상관관계를 분석하는 방법)
- 비지도 학습: 데이터의 결정값(정답)이 없는 경우

## 결정 계수
> **결정 계수**는 회귀 모델의 예측 결과에 대한 평가지표이다.
> - 회귀의 평가는 모든 타겟에 대해 (타겟값 - 예측값)의 크기가 얼마나 되는지를 확인해서 계산하게 된다.
> - 예측의 정확도가 낮아질수록 결정 계수가 작아진다. (정확하게 예측했을 때의 결정 계수 값은 1이다.)

**결정계수 = 1 - (타겟 - 예측)^2의 합 / (타겟 - 평균)^2의 합**

1. `from sklearn.neighbors import KNeighborsRegressor`
2. `knr = KNeighborsRegressor()`: 객체 인스턴스 생성
3. `knr.fit(train_input, train_target)`으로 훈련을 하고 `knr.score(test_input, test_target)`으로 결정계수를 계산한다.
4. 이 때, 더 직관적인 지표인 **MAE**를 사용할 수 있다. 이는 타겟값과 예측값의 절대값 오차의 평균을 나타낸다.
    - `test_pred = knr.predict(test_input)`: 평가데이터의 예측값
    - `mae = mean_absolute_error(test_target, test_pred)`: 평가데이터의 예측값과 평가 데이터의 타겟값의 절대값 오차를 계산한다. (예측값이 타겟값과 얼마나 다른지 보여준다.)


## 과대적합과 과소적합
|term|case|description|
|---|---|---|
|과대적합|train_input의 score > test_input의 score|학습데이터만 너무 정확하게 훈련하여 학습데이터로는 예측을 정확하게 하지만 다른 데이터에서는 낮은 성능을 나타내는 모델|
|과소적합|train_input의 score < test_input의 score, 두 score 다 낮은 수치를 보일 때|부족한 학습으로 인해 성능이 학습, 평가 데이터에서 모두 낮게 나올 때 (데이터의 수를 늘리거나 파라미터 조정(`n_neighbors`)을 통해 해결한다.)|

- 차이가 미미할 때는 과대적합과 과소적합을 판별하는 것이 상관 없음
- 하지만 차이가 많이 나면 **과대적합**의 경우 훈련데이터에만 맞는 모델이 되거나 **과소적합**의 경우 훈련을 너무 적게 해서 성능이 굉장히 떨어지는 모델이 될 수도 있다.